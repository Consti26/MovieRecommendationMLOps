FROM python:3.9-slim

WORKDIR /home/api_inference_content/

# Copy necessary files
COPY ./inference/requirements.txt .
COPY ./inference/api_inference_content.py .
COPY ./tfidf_vectorizer_model/__init__.py .
COPY ./tfidf_vectorizer_model/tfidf_vectorizer_model.py .

# Install dependencies using pip
RUN pip install --no-cache-dir -r requirements.txt

# Use ARG to accept build-time variable
ARG INFERENCE_PORT
# ENV PORT=${DATABASE_PORT}

# Expose the application port
EXPOSE ${INFERENCE_PORT}
RUN echo "The training port is: ${INFERENCE_PORT}"

# Run the application
CMD ["sh", "-c", "uvicorn api_inference_content:app --host 0.0.0.0 --port ${INFERENCE_PORT}"]
